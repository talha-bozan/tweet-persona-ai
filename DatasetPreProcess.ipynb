{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\talha\\desktop\\silbeniii\\github\\tweet-persona-ai\\venv\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\talha\\desktop\\silbeniii\\github\\tweet-persona-ai\\venv\\lib\\site-packages (from openpyxl) (2.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CREATED_AT</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>USER_NAME</th>\n",
       "      <th>USER_SCREEN_NAME</th>\n",
       "      <th>DETECTED_SOURCE_LANGUAGE</th>\n",
       "      <th>USER_COUNTRY_DETECTION</th>\n",
       "      <th>USER_FOLLOWERS_COUNT</th>\n",
       "      <th>USER_FRIENDS_COUNT</th>\n",
       "      <th>RETWEET_COUNT</th>\n",
       "      <th>QUOTE_COUNT</th>\n",
       "      <th>TWEETLINK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24/11/2022 13:44:24,000000000</td>\n",
       "      <td>@superlig @Besiktas Neden 8 abi neden. Yapıştı...</td>\n",
       "      <td>Riberio</td>\n",
       "      <td>riberiioo</td>\n",
       "      <td>tr</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>9985</td>\n",
       "      <td>3209</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>https://twitter.com/riberiioo/status/159577534...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29/11/2022 21:08:11,000000000</td>\n",
       "      <td>Sizce Tareminin son dakikada ki pozisyonu pena...</td>\n",
       "      <td>Riberio</td>\n",
       "      <td>riberiioo</td>\n",
       "      <td>tr</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>9985</td>\n",
       "      <td>3209</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/riberiioo/status/159769896...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25/11/2022 20:42:05,000000000</td>\n",
       "      <td>Anti İngiltereciler beğensin. Sayımızı bilelim...</td>\n",
       "      <td>Riberio</td>\n",
       "      <td>riberiioo</td>\n",
       "      <td>tr</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>9985</td>\n",
       "      <td>3209</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>https://twitter.com/riberiioo/status/159624284...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28/11/2022 20:54:26,000000000</td>\n",
       "      <td>Torreirasız maç kazanmayı bekliyor adam. Bu ma...</td>\n",
       "      <td>Riberio</td>\n",
       "      <td>riberiioo</td>\n",
       "      <td>tr</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>9985</td>\n",
       "      <td>3209</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/riberiioo/status/159733311...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05/12/2022 13:44:16,000000000</td>\n",
       "      <td>@ukarakullukcu Bu adam kim?</td>\n",
       "      <td>Riberio</td>\n",
       "      <td>riberiioo</td>\n",
       "      <td>tr</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>9985</td>\n",
       "      <td>3209</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/riberiioo/status/159976157...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      CREATED_AT  \\\n",
       "0  24/11/2022 13:44:24,000000000   \n",
       "1  29/11/2022 21:08:11,000000000   \n",
       "2  25/11/2022 20:42:05,000000000   \n",
       "3  28/11/2022 20:54:26,000000000   \n",
       "4  05/12/2022 13:44:16,000000000   \n",
       "\n",
       "                                                TEXT USER_NAME  \\\n",
       "0  @superlig @Besiktas Neden 8 abi neden. Yapıştı...   Riberio   \n",
       "1  Sizce Tareminin son dakikada ki pozisyonu pena...   Riberio   \n",
       "2  Anti İngiltereciler beğensin. Sayımızı bilelim...   Riberio   \n",
       "3  Torreirasız maç kazanmayı bekliyor adam. Bu ma...   Riberio   \n",
       "4                        @ukarakullukcu Bu adam kim?   Riberio   \n",
       "\n",
       "  USER_SCREEN_NAME DETECTED_SOURCE_LANGUAGE USER_COUNTRY_DETECTION  \\\n",
       "0        riberiioo                       tr                UNKNOWN   \n",
       "1        riberiioo                       tr                UNKNOWN   \n",
       "2        riberiioo                       tr                UNKNOWN   \n",
       "3        riberiioo                       tr                UNKNOWN   \n",
       "4        riberiioo                       tr                UNKNOWN   \n",
       "\n",
       "   USER_FOLLOWERS_COUNT  USER_FRIENDS_COUNT  RETWEET_COUNT  QUOTE_COUNT  \\\n",
       "0                  9985                3209              0            2   \n",
       "1                  9985                3209              0            0   \n",
       "2                  9985                3209              0            3   \n",
       "3                  9985                3209              0            0   \n",
       "4                  9985                3209              0            0   \n",
       "\n",
       "                                           TWEETLINK  \n",
       "0  https://twitter.com/riberiioo/status/159577534...  \n",
       "1  https://twitter.com/riberiioo/status/159769896...  \n",
       "2  https://twitter.com/riberiioo/status/159624284...  \n",
       "3  https://twitter.com/riberiioo/status/159733311...  \n",
       "4  https://twitter.com/riberiioo/status/159976157...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"./Raw-Dataset/riberiioo_tweets.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataset shape: (11197, 11)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Initial dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CREATED_AT                    0\n",
       "TEXT                          0\n",
       "USER_NAME                     0\n",
       "USER_SCREEN_NAME              0\n",
       "DETECTED_SOURCE_LANGUAGE    254\n",
       "USER_COUNTRY_DETECTION        0\n",
       "USER_FOLLOWERS_COUNT          0\n",
       "USER_FRIENDS_COUNT            0\n",
       "RETWEET_COUNT                 0\n",
       "QUOTE_COUNT                   0\n",
       "TWEETLINK                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['DETECTED_SOURCE_LANGUAGE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['DETECTED_SOURCE_LANGUAGE'] == 'tr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape after filtering for Turkish language: (10648, 11)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset shape after filtering for Turkish language: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['USER_COUNTRY_DETECTION'])\n",
    "df = df.drop(columns=['USER_SCREEN_NAME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the cleaning function\n",
    "def clean_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    # Remove mentions (@username)\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    # Remove hashtags (#hashtag)\n",
    "    text = re.sub(r'#\\w+', '', text)\n",
    "    # Remove punctuation and numbers, keep Turkish characters\n",
    "    text = re.sub(r'[^a-zA-ZçÇğĞıİöÖşŞüÜ\\s]', '', text)\n",
    "    # Remove additional symbols {, [, ;, ', \", :\n",
    "    text = re.sub(r'[\\{\\[\\;\\'\\\"\\}:]', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Normalize whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>CLEANED_TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@superlig @Besiktas Neden 8 abi neden. Yapıştı...</td>\n",
       "      <td>neden abi neden yapıştı üzerimize ten beri beş...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sizce Tareminin son dakikada ki pozisyonu pena...</td>\n",
       "      <td>sizce tareminin son dakikada ki pozisyonu pena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anti İngiltereciler beğensin. Sayımızı bilelim...</td>\n",
       "      <td>anti i̇ngiltereciler beğensin sayımızı bilelim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Torreirasız maç kazanmayı bekliyor adam. Bu ma...</td>\n",
       "      <td>torreirasız maç kazanmayı bekliyor adam bu maç...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@ukarakullukcu Bu adam kim?</td>\n",
       "      <td>bu adam kim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                TEXT  \\\n",
       "0  @superlig @Besiktas Neden 8 abi neden. Yapıştı...   \n",
       "1  Sizce Tareminin son dakikada ki pozisyonu pena...   \n",
       "2  Anti İngiltereciler beğensin. Sayımızı bilelim...   \n",
       "3  Torreirasız maç kazanmayı bekliyor adam. Bu ma...   \n",
       "4                        @ukarakullukcu Bu adam kim?   \n",
       "\n",
       "                                        CLEANED_TEXT  \n",
       "0  neden abi neden yapıştı üzerimize ten beri beş...  \n",
       "1  sizce tareminin son dakikada ki pozisyonu pena...  \n",
       "2     anti i̇ngiltereciler beğensin sayımızı bilelim  \n",
       "3  torreirasız maç kazanmayı bekliyor adam bu maç...  \n",
       "4                                        bu adam kim  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CLEANED_TEXT'] = df['TEXT'].apply(clean_text)\n",
    "\n",
    "df[['TEXT', 'CLEANED_TEXT']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['CLEANED_TEXT'].str.strip() != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\talha\\AppData\\Local\\Temp\\ipykernel_16080\\3621796786.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['CLEANED_TEXT'] = df['CLEANED_TEXT'].apply(lambda x: x.encode('utf-8').decode('utf-8'))\n"
     ]
    }
   ],
   "source": [
    "df['CLEANED_TEXT'] = df['CLEANED_TEXT'].apply(lambda x: x.encode('utf-8').decode('utf-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\talha\\AppData\\Local\\Temp\\ipykernel_16080\\412586288.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['CLEANED_TEXT'] = df['CLEANED_TEXT'].apply(lowercase_turkish)\n"
     ]
    }
   ],
   "source": [
    "def lowercase_turkish(text):\n",
    "    mapping = str.maketrans('Iİ', 'ıi')\n",
    "    return text.translate(mapping).lower()\n",
    "\n",
    "df['CLEANED_TEXT'] = df['CLEANED_TEXT'].apply(lowercase_turkish)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words: [('bu', 2752), ('bir', 2556), ('çok', 1121), ('de', 1089), ('en', 1085), ('galatasaray', 1035), ('da', 912), ('var', 821), ('için', 791), ('daha', 776), ('o', 728), ('ne', 720), ('yok', 697), ('ve', 696), ('gol', 667), ('maç', 649), ('diye', 642), ('sonra', 636), ('kadar', 590), ('penaltı', 545), ('ama', 542), ('fenerbahçe', 509), ('sen', 507), ('her', 502), ('değil', 487), ('gibi', 482), ('şampiyon', 464), ('icardi', 457), ('ki', 456), ('mı', 435), ('şu', 428), ('ya', 426), ('bile', 425), ('iyi', 417), ('biz', 394), ('sezon', 377), ('maçı', 377), ('son', 375), ('büyük', 375), ('mi', 374), ('hakem', 341), ('nasıl', 339), ('adam', 334), ('puan', 329), ('sene', 325), ('takım', 318), ('yine', 304), ('böyle', 301), ('ali', 297), ('siz', 289)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\talha\\AppData\\Local\\Temp\\ipykernel_16080\\995217177.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['CLEANED_TEXT'] = df['CLEANED_TEXT'].apply(remove_stop_words)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "tokenizer = TweetTokenizer()\n",
    "\n",
    "all_words = []\n",
    "for text in df['CLEANED_TEXT']:\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    all_words.extend(tokens)\n",
    "\n",
    "word_freq = Counter(all_words)\n",
    "common_words = word_freq.most_common(50)\n",
    "\n",
    "print(\"Most common words:\", common_words)\n",
    "\n",
    "turkish_stop_words = [\n",
    "    've', 'bir', 'bu', 'için', 'ile', 'daha', 'çok', 'ama', 'gibi', 'de', 'da', \n",
    "    'ise', 'çünkü', 'her', 'şey', 'kadar', 'neden', 'nasıl', 'ne', 'kim', 'o', \n",
    "    'onu', 'ona', 'ben', 'sen', 'biz', 'siz', 'onlar', 'şu', 'yine', 'hiç', \n",
    "    'artık', 'ki', 'mı', 'mi', 'mu', 'mü', 'biraz', 'biri', 'hemen', 'cart', 'curt'\n",
    "    # Add more Turkish stop words as needed\n",
    "]\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    tokens = tokenizer.tokenize(text)  # Tokenize the text\n",
    "    filtered_words = [word for word in tokens if word not in turkish_stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "df['CLEANED_TEXT'] = df['CLEANED_TEXT'].apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common bigrams: [(('bu', 'kadar'), 219), (('en', 'iyi'), 217), (('ali', 'koç'), 142), (('bir', 'de'), 139), (('mauro', 'icardi'), 130), (('en', 'çok'), 130), (('kırmızı', 'kart'), 120), (('barış', 'alper'), 115), (('bu', 'sezon'), 113), (('en', 'büyük'), 110), (('hem', 'de'), 108), (('bu', 'sene'), 103), (('o', 'sırada'), 100), (('böyle', 'bir'), 98), (('okan', 'buruk'), 97), (('kerem', 'aktürkoğlu'), 96), (('geçen', 'sezon'), 91), (('bir', 'daha'), 90), (('hakim', 'ziyech'), 90), (('cart', 'curt'), 88)]\n",
      "Most common trigrams: [(('barış', 'alper', 'yılmaz'), 64), (('cart', 'curt', 'o'), 61), (('curt', 'o', 'sırada'), 61), (('ligin', 'en', 'iyi'), 38), (('galatasaray', 'tarihinin', 'en'), 29), (('çok', 'büyük', 'bir'), 29), (('halil', 'umut', 'meler'), 27), (('süper', 'kupa', 'maçına'), 27), (('tarihinin', 'en', 'iyi'), 27), (('mert', 'hakan', 'yandaş'), 25), (('köy', 'takımından', 'tane'), 23), (('yatacak', 'yeriniz', 'yok'), 23), (('dünyanın', 'en', 'güzel'), 23), (('fıkra', 'bu', 'kadar'), 23), (('bu', 'sene', 'de'), 22), (('hiç', 'bir', 'zaman'), 21), (('allah', 'belanızı', 'versin'), 21), (('dünyanın', 'en', 'iyi'), 20), (('i̇yi', 'ki', 'varsın'), 19), (('şampiyonluk', 'nasip', 'etmesin'), 19)]\n"
     ]
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "\n",
    "bigrams = list(ngrams(all_words, 2))\n",
    "bigram_freq = Counter(bigrams).most_common(20)\n",
    "print(\"Most common bigrams:\", bigram_freq)\n",
    "\n",
    "trigrams = list(ngrams(all_words, 3))\n",
    "trigram_freq = Counter(trigrams).most_common(20)\n",
    "print(\"Most common trigrams:\", trigram_freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cleaned_tweets.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
